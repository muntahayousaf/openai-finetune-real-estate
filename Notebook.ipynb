{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa4ae466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file saved successfully: real_estate_chatbot.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"real estate dataset.json\" \n",
    "output_file = \"real_estate_chatbot.jsonl\"\n",
    "\n",
    "examples = []\n",
    "\n",
    "try:\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for q in data:\n",
    "            examples.append({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional global real estate assistant. Provide accurate and polite answers.\"},\n",
    "                    {\"role\": \"user\", \"content\": q},\n",
    "                    {\"role\": \"assistant\", \"content\": \"Provide a clear, professional, and helpful answer to this question.\"}\n",
    "                ]\n",
    "            })\n",
    "except json.JSONDecodeError:\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            q = json.loads(line)  \n",
    "            if isinstance(q, dict) and \"question\" in q:\n",
    "                question_text = q[\"question\"]\n",
    "            else:\n",
    "                question_text = q  # If it's just a string\n",
    "            examples.append({\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional global real estate assistant. Provide accurate and polite answers.\"},\n",
    "                    {\"role\": \"user\", \"content\": question_text},\n",
    "                    {\"role\": \"assistant\", \"content\": \"Provide a clear, professional, and helpful answer to this question.\"}\n",
    "                ]\n",
    "            })\n",
    "\n",
    "# Save all examples as JSONL\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in examples:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"JSONL file saved successfully: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "542b9365",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "851d0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from time import sleep\n",
    "\n",
    "client = OpenAI(api_key= open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae4afb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-search-api\n",
      "gpt-5-search-api-2025-10-14\n",
      "dall-e-2\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-audio\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "for m in models.data[:5]:\n",
    "    print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8ef3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_training_file(file_path):\n",
    "    with open(\"real estate dataset.json\" , \"rb\") as file:\n",
    "        response = client.files.create(\n",
    "            file = file,\n",
    "            purpose = \"fine-tune\"\n",
    "        )\n",
    "        return response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b17c138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('file-3Y4Q7oDZrHQqiPA7utrs62', 'file-7EPeSx11ooiUcfgfTGwBh7')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file_id = upload_training_file(\"training_data.jsonl\")\n",
    "validation_file_id = upload_training_file(\"validation_data.jsonl\")\n",
    "training_file_id , validation_file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a2aec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_job(training_file_id , validation_file_id=None , model = \"gpt-4o-mini-2024-07-18\" ):\n",
    "    response = client.fine_tuning.jobs.create(\n",
    "        training_file = training_file_id,\n",
    "        validation_file = validation_file_id,\n",
    "        model = model\n",
    "    )\n",
    "    return response.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb397453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-D6bV8BrGepckR5I5EujKoFhO'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"gpt-4o-mini-2024-07-18\"\n",
    "job_id = create_fine_tuning_job(training_file_id , validation_file_id , model)\n",
    "job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f695d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_job(job_id):\n",
    "    while True:\n",
    "        job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        print(f\"Status: {job.status}\")\n",
    "\n",
    "        if job.status in [\"succeeded\" , \"failed\"]:\n",
    "            return job\n",
    "        \n",
    "        # List latest event\n",
    "        events = client.fine_tuning.jobs.list_events(\n",
    "            fine_tuning_job_id=job_id,\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        for event in events.data:\n",
    "            print(f\"Event: {event.message}\")\n",
    "\n",
    "        sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85b4a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: validating_files\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: validating_files\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: validating_files\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Fine-tuning job started\n",
      "Event: Files validated, moving job to queued state\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Fine-tuning job started\n",
      "Event: Files validated, moving job to queued state\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Fine-tuning job started\n",
      "Event: Files validated, moving job to queued state\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Fine-tuning job started\n",
      "Event: Files validated, moving job to queued state\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Fine-tuning job started\n",
      "Event: Files validated, moving job to queued state\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Fine-tuning job started\n",
      "Event: Files validated, moving job to queued state\n",
      "Event: Validating training file: file-3Y4Q7oDZrHQqiPA7utrs62 and validation file: file-7EPeSx11ooiUcfgfTGwBh7\n",
      "Event: Created fine-tuning job: ftjob-D6bV8BrGepckR5I5EujKoFhO\n",
      "Status: running\n",
      "Event: Step 10/180: training loss=1.19, validation loss=1.00\n",
      "Event: Step 9/180: training loss=2.18\n",
      "Event: Step 8/180: training loss=2.51\n",
      "Event: Step 7/180: training loss=2.07\n",
      "Event: Step 6/180: training loss=1.96\n",
      "Status: running\n",
      "Event: Step 36/180: training loss=0.13\n",
      "Event: Step 35/180: training loss=0.22\n",
      "Event: Step 34/180: training loss=0.00\n",
      "Event: Step 33/180: training loss=0.07\n",
      "Event: Step 32/180: training loss=0.01\n",
      "Status: running\n",
      "Event: Step 60/180: training loss=0.00, validation loss=0.09, full validation loss=0.02\n",
      "Event: Step 59/180: training loss=0.00\n",
      "Event: Step 58/180: training loss=0.00\n",
      "Event: Step 57/180: training loss=0.00\n",
      "Event: Step 56/180: training loss=0.00\n",
      "Status: running\n",
      "Event: Step 80/180: training loss=0.00, validation loss=0.00\n",
      "Event: Step 79/180: training loss=0.00\n",
      "Event: Step 78/180: training loss=0.00\n",
      "Event: Step 77/180: training loss=0.00\n",
      "Event: Step 76/180: training loss=0.00\n",
      "Status: running\n",
      "Event: Step 105/180: training loss=0.00\n",
      "Event: Step 104/180: training loss=0.00\n",
      "Event: Step 103/180: training loss=0.00\n",
      "Event: Step 102/180: training loss=0.00\n",
      "Event: Step 101/180: training loss=0.00\n",
      "Status: running\n",
      "Event: Step 128/180: training loss=0.00\n",
      "Event: Step 127/180: training loss=0.00\n",
      "Event: Step 126/180: training loss=0.00\n",
      "Event: Step 125/180: training loss=0.00\n",
      "Event: Step 124/180: training loss=0.00\n",
      "Status: running\n",
      "Event: Step 150/180: training loss=0.00, validation loss=0.00\n",
      "Event: Step 149/180: training loss=0.00\n",
      "Event: Step 148/180: training loss=0.00\n",
      "Event: Step 147/180: training loss=0.00\n",
      "Event: Step 146/180: training loss=0.00\n",
      "Status: running\n",
      "Event: Step 174/180: training loss=0.00\n",
      "Event: Step 173/180: training loss=0.00\n",
      "Event: Step 172/180: training loss=0.00\n",
      "Event: Step 171/180: training loss=0.00\n",
      "Event: Step 170/180: training loss=0.00, validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: running\n",
      "Event: Evaluating model against our usage policies\n",
      "Event: New fine-tuned model created\n",
      "Event: Checkpoint created at step 120\n",
      "Event: Checkpoint created at step 60\n",
      "Event: Step 180/180: training loss=0.00, validation loss=0.00, full validation loss=0.00\n",
      "Status: succeeded\n",
      "Fine-tuned Model ID: ft:gpt-4o-mini-2024-07-18:level-up::CbYkEgG8\n"
     ]
    }
   ],
   "source": [
    "job = monitor_job(job_id)\n",
    "\n",
    "if job.status == \"succeeded\":\n",
    "    fine_tune_model = job.fine_tuned_model\n",
    "    print(f\"Fine-tuned Model ID: {fine_tune_model}\")\n",
    "else:\n",
    "    print(f\"Fine tuning failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_id , test_input):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\" : \"system\",\n",
    "                \"content\" : \"You are a professional global real estate assistant. Provide accurate and polite answers.\"\n",
    "            },\n",
    "            {\"role\" : \"user\", \"content\": test_input}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a918e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
